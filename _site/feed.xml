<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-12-16T22:56:33+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Dato’s blog</title><subtitle>Description is not found, yet.
</subtitle><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/jekyll/update/2017/08/29/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2017-08-29T06:34:22+08:00</published><updated>2017-08-29T06:34:22+08:00</updated><id>http://localhost:4000/jekyll/update/2017/08/29/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2017/08/29/welcome-to-jekyll.html">&lt;p&gt;You’ll find this post in your &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;p&gt;To add new posts, simply add a file in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory that follows the convention &lt;code class=&quot;highlighter-rouge&quot;&gt;YYYY-MM-DD-name-of-post.ext&lt;/code&gt; and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.&lt;/p&gt;

&lt;p&gt;Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Tom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints 'Hi, Tom' to STDOUT.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Check out the &lt;a href=&quot;https://jekyllrb.com/docs/home&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll’s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.</summary></entry><entry><title type="html">A Simple Unified Formulation of Value-based Approach, Policy Gradient Approach and Actor-Critic Approach</title><link href="http://localhost:4000/none/yet/2017/08/29/DAGMM-A-Deep-Learning-Model-for-Anomaly-Detection.html" rel="alternate" type="text/html" title="A Simple Unified Formulation of Value-based Approach, Policy Gradient Approach and Actor-Critic Approach" /><published>2017-08-29T06:34:22+08:00</published><updated>2017-08-29T06:34:22+08:00</updated><id>http://localhost:4000/none/yet/2017/08/29/DAGMM-A-Deep-Learning-Model-for-Anomaly-Detection</id><content type="html" xml:base="http://localhost:4000/none/yet/2017/08/29/DAGMM-A-Deep-Learning-Model-for-Anomaly-Detection.html">&lt;p&gt;Consider a reinforcement learning defined by $(\mathcal{S},\mathcal{A},\mathcal{T},\mathcal{R},\gamma)$ which represents a tuple of state space, action space, transition probability, reward function and discount rate. In particular, $\mathcal{T}$ is a mapping $\mathcal{S}\times\mathcal{A}\times\mathcal{S}\to[0,1]$ and $\mathcal{R}$ a mapping $\mathcal{S}\times\mathcal{A}\times\mathcal{S}\times\mathbb{R}\to[0,1]$, where $\mathbb{R}$ denotes the domain of real numbers.&lt;/p&gt;

&lt;h3 id=&quot;policy-form&quot;&gt;Policy Form&lt;/h3&gt;

&lt;p&gt;The value function with respect to a policy $\pi$ is defined as:
&lt;script type=&quot;math/tex&quot;&gt;V(s)=\sum_{a\in\mathcal{A}}\pi(s,a)\sum_{s'\in\mathcal{S}}\mathcal{T}(s,a,s')(\sum_{r\in\mathbb{R}}r\mathcal{R}(s,a,s',r)+\gamma V(s'))&lt;/script&gt;
The value of the policy is then
&lt;script type=&quot;math/tex&quot;&gt;J=\sum_{s\in\mathcal{S}}\rho(s)V(s)&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;value-based-approaches&quot;&gt;Value-based Approaches&lt;/h4&gt;

&lt;p&gt;Value-based approaches is formulated by a quality function $Q_\theta(s,a)$. Denote $Q_{\theta,s}$ the vector $(Q_\theta(s,a))_{a\in\mathcal{A}}$ for notational convenience:
&lt;script type=&quot;math/tex&quot;&gt;\pi_{value,\theta}(s):=f(Q_{\theta,s})&lt;/script&gt;
where $f$ can be the indicator of maximum or a temperated softmax operation or any other probability-smoothing function.
&lt;script type=&quot;math/tex&quot;&gt;\partial_\theta\pi_{value,\theta}(s):=\partial_\theta(Q_{\theta,s})\nabla f(Q_{\theta,s})&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;policy-gradient-approaches&quot;&gt;Policy Gradient Approaches&lt;/h4&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;zong2018deep&quot;&gt;[1]B. Zong, Q. Song, M.R. Min, W. Cheng, C. Lumezanu, D. Cho, H. Chen, Deep autoencoding gaussian mixture model for unsupervised anomaly detection, (2018).&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name></name></author><summary type="html">Consider a reinforcement learning defined by $(\mathcal{S},\mathcal{A},\mathcal{T},\mathcal{R},\gamma)$ which represents a tuple of state space, action space, transition probability, reward function and discount rate. In particular, $\mathcal{T}$ is a mapping $\mathcal{S}\times\mathcal{A}\times\mathcal{S}\to[0,1]$ and $\mathcal{R}$ a mapping $\mathcal{S}\times\mathcal{A}\times\mathcal{S}\times\mathbb{R}\to[0,1]$, where $\mathbb{R}$ denotes the domain of real numbers.</summary></entry></feed>